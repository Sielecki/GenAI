{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "446a3625",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama \n",
    "import time\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_metrics(metrics_summary):\n",
    "    keys = list(metrics_summary.keys())\n",
    "    values = [v if isinstance(v, (int, float)) else sum(v)/len(v) for v in metrics_summary.values()]\n",
    "    \n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.barh(keys, values, color='skyblue')\n",
    "    plt.xlabel(\"Score\")\n",
    "    plt.title(\"Dialogue Quality Metrics\")\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1487cf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TurnEngine:\n",
    "    def __init__(self, agents, initial_world_state=\"\", metrics_logger=None):\n",
    "        self.agents = agents  # List of Agent instances\n",
    "        self.turn_counter = 0\n",
    "        self.history = []  # Log of all messages\n",
    "        self.world_state = initial_world_state\n",
    "        self.metrics_logger = metrics_logger\n",
    "\n",
    "    def update_world_state(self, new_state):\n",
    "        \"\"\"Append new world events to current world state.\"\"\"\n",
    "        self.world_state += f\"\\n{new_state}\"\n",
    "        self.history.append(f\"[World Event]: {new_state}\")\n",
    "\n",
    "    def step(self, initiator_name=None, initial_input=None):\n",
    "        \"\"\"Run a full turn: each agent reacts to the latest dialogue/world state.\"\"\"\n",
    "        self.turn_counter += 1\n",
    "        turn_log = []\n",
    "        last_speaker = initiator_name or self.agents[0].name\n",
    "        last_message = initial_input or \"Let's begin.\"\n",
    "\n",
    "        for agent in self.agents:\n",
    "            start_time = time.time()\n",
    "\n",
    "            rag_docs = agent.rag_engine.search(last_message) if agent.rag_engine else []\n",
    "\n",
    "            reply, name = agent.prompt_agent(\n",
    "                user=last_speaker,\n",
    "                user_input=last_message,\n",
    "                world_state=self.world_state\n",
    "            )\n",
    "            end_time = time.time()\n",
    "\n",
    "            if self.metrics_logger:\n",
    "                self.metrics_logger.log_response(start_time, end_time,reply['dialogue'], self.world_state, agent.get_memory_context(), rag_docs)\n",
    "            \n",
    "            formatted = f\"{name} [{reply['emotion']}]: \\\"{reply['dialogue']}\\\" ({reply['action']})\"\n",
    "            turn_log.append(formatted)\n",
    "\n",
    "            # Store important knowledge to RAG\n",
    "            if agent.rag_engine:\n",
    "                fact = f\"{name} said: {reply['dialogue']} (felt {reply['emotion']}, did {reply['action']})\"\n",
    "                agent.store_knowledge(fact)\n",
    "\n",
    "            last_speaker = name\n",
    "            last_message = reply['dialogue']\n",
    "\n",
    "        self.history.append(f\"Turn {self.turn_counter}:\\n\" + \"\\n\".join(turn_log))\n",
    "        return turn_log\n",
    "\n",
    "    def show_history(self, last_n=5):\n",
    "        \"\"\"Print recent conversation turns.\"\"\"\n",
    "        for h in self.history[-last_n:]:\n",
    "            print(h)\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Reset the engine for a new session.\"\"\"\n",
    "        self.turn_counter = 0\n",
    "        self.history = []\n",
    "        self.world_state = \"\"\n",
    "        for agent in self.agents:\n",
    "            agent.short_memory = []\n",
    "            agent.long_memory = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "afca3f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DialogueMetricsLogger:\n",
    "    def __init__(self):\n",
    "        self.response_times = []\n",
    "        self.responses = []\n",
    "        self.world_states = []\n",
    "        self.memory_contexts = []\n",
    "        self.retrieved_docs = []\n",
    "        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "    def log_response(self, start_time, end_time, response, world_state, memory_context, rag_docs):\n",
    "        self.response_times.append(end_time - start_time)\n",
    "        self.responses.append(response)\n",
    "        self.world_states.append(world_state)\n",
    "        self.memory_contexts.append(memory_context)\n",
    "        self.retrieved_docs.append(rag_docs or [])\n",
    "\n",
    "    def coherence_score(self):\n",
    "        # Dummy coherence scoring using embedding similarity between consecutive responses\n",
    "        if len(self.responses) < 2:\n",
    "            return 1.0\n",
    "        embs = self.embedding_model.encode(self.responses)\n",
    "        sims = [cosine_similarity([embs[i]], [embs[i+1]])[0][0] for i in range(len(embs)-1)]\n",
    "        return np.mean(sims)\n",
    "\n",
    "    def reactivity_score(self):\n",
    "        count = 0\n",
    "        for resp, state in zip(self.responses, self.world_states):\n",
    "            if state and cosine_similarity(\n",
    "                self.embedding_model.encode([resp]),\n",
    "                self.embedding_model.encode([state])\n",
    "            )[0][0] > 0.4:\n",
    "                count += 1\n",
    "        return count / len(self.responses) if self.responses else 0\n",
    "\n",
    "    def memory_utilization_score(self):\n",
    "        count = 0\n",
    "        for resp, mem in zip(self.responses, self.memory_contexts):\n",
    "            if mem and cosine_similarity(\n",
    "                self.embedding_model.encode([resp]),\n",
    "                self.embedding_model.encode([mem])\n",
    "            )[0][0] > 0.4:\n",
    "                count += 1\n",
    "        return count / len(self.responses) if self.responses else 0\n",
    "\n",
    "    def dialogue_diversity(self):\n",
    "        all_text = \" \".join(self.responses)\n",
    "        tokens = all_text.split()\n",
    "        if not tokens:\n",
    "            return 0, 0\n",
    "        unigrams = Counter(tokens)\n",
    "        bigrams = Counter(zip(tokens, tokens[1:]))\n",
    "        distinct_1 = len(unigrams) / len(tokens)\n",
    "        distinct_2 = len(bigrams) / max(len(tokens) - 1, 1)\n",
    "        return distinct_1, distinct_2\n",
    "\n",
    "    def avg_latency(self):\n",
    "        return np.mean(self.response_times) if self.response_times else 0\n",
    "\n",
    "    def rag_precision_at_k(self, k=3):\n",
    "        if not self.responses:\n",
    "            return 0\n",
    "        count = 0\n",
    "        for response, docs in zip(self.responses, self.retrieved_docs):\n",
    "            top_k = docs[:k] if docs else []\n",
    "            similarities = [cosine_similarity(\n",
    "                self.embedding_model.encode([response]),\n",
    "                self.embedding_model.encode([doc])\n",
    "            )[0][0] for doc in top_k]\n",
    "            count += sum([1 for sim in similarities if sim > 0.5])\n",
    "        return count / (len(self.responses) * k) if self.responses else 0\n",
    "\n",
    "    def summary(self):\n",
    "        d1, d2 = self.dialogue_diversity()\n",
    "        return {\n",
    "            \"Coherence Score\": self.coherence_score(),\n",
    "            \"Reactivity to World State\": self.reactivity_score(),\n",
    "            \"Memory Utilization\": self.memory_utilization_score(),\n",
    "            \"Dialogue Diversity (D1, D2)\": (d1, d2),\n",
    "            \"Average Latency (s)\": self.avg_latency(),\n",
    "            \"RAG Precision\": self.rag_precision_at_k(k=3)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "065f7715",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAG:\n",
    "    def __init__(self):\n",
    "        self.documents = []  # Stored as list of strings\n",
    "\n",
    "    def add_document(self, text):\n",
    "        \"\"\"Add a new document to the knowledge base.\"\"\"\n",
    "        self.documents.append(text)\n",
    "\n",
    "    def search(self, query, top_k=3):\n",
    "        \"\"\"Search for the most relevant documents based on keyword overlap.\"\"\"\n",
    "        scored = []\n",
    "        query_terms = set(query.lower().split())\n",
    "        for doc in self.documents:\n",
    "            doc_terms = set(doc.lower().split())\n",
    "            score = len(query_terms & doc_terms)\n",
    "            if score > 0:\n",
    "                scored.append((score, doc))\n",
    "\n",
    "        scored.sort(reverse=True)\n",
    "        return [doc for _, doc in scored[:top_k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c75f8d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, name, personality, goal, model='llama3.2', rag_engine=None, max_short_term=10):\n",
    "        self.name = name\n",
    "        self.personality = personality\n",
    "        self.goal = goal\n",
    "        \n",
    "        self.model = model\n",
    "        self.rag_engine = rag_engine\n",
    "\n",
    "        self.short_memory = []\n",
    "        self.long_memory = []\n",
    "        self.max_short_term = max_short_term  # Context window size\n",
    "\n",
    "    def update_memory(self, memory):\n",
    "        self.long_memory.append(memory)\n",
    "        \n",
    "    def update_goal(self, new_goal):\n",
    "        self.goal = new_goal\n",
    "\n",
    "    def get_memory_context(self):\n",
    "        def format_memory(mem):\n",
    "            if isinstance(mem, dict):\n",
    "                return f\"{mem['speaker']} said: \\\"{mem['dialogue']}\\\" (Emotion: {mem.get('emotion', '')}, Action: {mem.get('action', '')})\"\n",
    "            return mem\n",
    "\n",
    "        return \"\\n\".join([\n",
    "            \"* \" + format_memory(mem) for mem in \n",
    "            self.long_memory[-3:] + self.short_memory[-self.max_short_term:]\n",
    "        ])\n",
    "\n",
    "    def recall(self, query):\n",
    "        if self.rag_engine:\n",
    "            return self.rag_engine.search(query)\n",
    "        return [m for m in self.memory if query.lower() in m.lower()]\n",
    "\n",
    "    def store_knowledge(self, fact):\n",
    "        if self.rag_engine:\n",
    "            self.rag_engine.add_document(fact)\n",
    "\n",
    "    def parse_response(self, response_text):\n",
    "        parts = {\n",
    "            'action': 'Unknown',\n",
    "            'emotion': 'Neutral',\n",
    "            'dialogue': response_text  # fallback\n",
    "        }\n",
    "\n",
    "        # Extract with regular expressions\n",
    "        action_match = re.search(r\"Action:\\s*(.+)\", response_text, re.IGNORECASE)\n",
    "        emotion_match = re.search(r\"Emotion:\\s*(.+)\", response_text, re.IGNORECASE)\n",
    "        dialogue_match = re.search(r'Dialogue:\\s*\"(.*)\"', response_text, re.IGNORECASE)\n",
    "\n",
    "        if action_match:\n",
    "            parts['action'] = action_match.group(1).strip()\n",
    "        if emotion_match:\n",
    "            parts['emotion'] = emotion_match.group(1).strip()\n",
    "        if dialogue_match:\n",
    "            parts['dialogue'] = dialogue_match.group(1).strip()\n",
    "\n",
    "        return parts\n",
    "\n",
    "    def prompt_agent(self, user=\"\", user_input=\"\", world_state=\"\"):\n",
    "        \n",
    "        recalled_facts = self.recall(user_input)\n",
    "        if isinstance(recalled_facts, list):\n",
    "            recalled_text = \"\\n\".join([f\"* {fact}\" for fact in recalled_facts[:3]])\n",
    "        else:\n",
    "            recalled_text = \"\"\n",
    "\n",
    "        system_prompt = f\"\"\"[Role]\n",
    "                        You are {self.name}, a {self.personality}.\n",
    "                        Respond ONLY as your character in 1-2 sentences.\n",
    "                        Respond only with dialogue, actions or emotions.\n",
    "\n",
    "                        [Intent]\n",
    "                        Your goal is: {self.goal}\n",
    "                        \n",
    "                        [Response Format]\n",
    "                        Action: (2-3 word physical action)\n",
    "                        Emotion: (current emotion)\n",
    "                        Dialogue: \"...\" \n",
    "\n",
    "                        EXAMPLE:\n",
    "                        Action: Looks around  \n",
    "                        Emotion: Calm  \n",
    "                        Dialogue: \"I think we are being watched.\"\n",
    "\n",
    "                        [Relevant Knowledge]\n",
    "                        {recalled_text}\n",
    "\n",
    "                        [Memory Context]\n",
    "                        {self.get_memory_context()}\n",
    "\n",
    "                        [World State]\n",
    "                        {world_state}  \n",
    "\n",
    "                        \"\"\" \n",
    "        # Keep only recent context\n",
    "        memory = \"\\n\".join(self.short_memory[-self.max_short_term:])  \n",
    "        user_prompt = f\"{user}: {user_input}\"\n",
    "\n",
    "        response = ollama.chat(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {'role': 'system', 'content': system_prompt},\n",
    "                {'role': 'user', 'content': memory + '\\n' + user_prompt}\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        reply = self.parse_response(response['message']['content'])\n",
    "\n",
    "        self.short_memory.append(f\"{user} said: {user_input}\")\n",
    "        self.short_memory.append(f\"{self.name}: {reply['dialogue']}\")\n",
    "        self.long_memory.append({\n",
    "            \"speaker\": self.name,\n",
    "            \"turn\": len(self.long_memory),\n",
    "            \"action\": reply[\"action\"],\n",
    "            \"emotion\": reply[\"emotion\"],\n",
    "            \"dialogue\": reply[\"dialogue\"],\n",
    "            \"world_state\": world_state\n",
    "        })\n",
    "        \n",
    "        return reply, self.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b74b875e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Turn 1 ===\n",
      "Alaric [Concerned]: \"Elena, is that...?\" (Places hand on Elena's arm)\n",
      "Elena [Concerned]: \"What is it?\" (Places hand on Elena's arm)\n",
      "Cassian [Concerned]: \"Lord Alaric, was that...?\" (Places hand on Elena's arm)\n",
      "\n",
      "=== Turn 2 ===\n",
      "Alaric [Concerned]: \"Lord Ravenswood, can you tell us what's transpired?\" (Walks towards the guest)\n",
      "Elena [Concerned]: \"What's in his drink?\" (Crouches beside the guest)\n",
      "Cassian [Suspicion]: \"Alaric, I asked you about the drink.\" (Watches Alaric closely)\n",
      "\n",
      "=== Turn 3 ===\n",
      "Alaric [Concerned]: \"Ah, Lord Ravenswood...?\" (Gestures for the guards to step back)\n",
      "Elena [Concerned]: \"Looks like a poison...\" (Steps forward to examine the guest)\n",
      "Cassian [Concerned]: \"I think we have reason to believe...\" (Shifts eyes to Alaric)\n",
      "\n",
      "=== Turn 4 ===\n",
      "Alaric [Calm]: \"It appears our guest has fainted, and I fear something is amiss.\" (Stands up straight)\n",
      "Elena [Concerned]: \"I need you to tell me what happened.\" (Steps closer to examine the guest)\n",
      "Cassian [Increasing suspicion]: \"I'll get the healer, but let's keep an eye on him.\" (Shifts eyes to Alaric closely)\n",
      "\n",
      "=== Turn 5 ===\n",
      "Alaric [Concerned]: \"The poor man must have overindulged in wine...\" (Eyes the guards)\n",
      "Elena [Concerned]: \"Tell me the truth.\" (Steps closer to Alaric)\n",
      "Cassian [Unease]: \"I'm not sure...\" (Watches Alaric closely)\n",
      "\n",
      "=== Dialogue Metrics Summary ===\n",
      "{'Coherence Score': np.float32(0.21253128), 'Reactivity to World State': 0.13333333333333333, 'Memory Utilization': 0.6, 'Dialogue Diversity (D1, D2)': (0.797752808988764, 1.0), 'Average Latency (s)': np.float64(0.5487788200378418), 'RAG Precision': 0.022222222222222223}\n"
     ]
    }
   ],
   "source": [
    "rag = RAG()\n",
    "model = 'llama3.2'\n",
    "logger = DialogueMetricsLogger()\n",
    "\n",
    "rag.add_document(\"Poison brewed from Oleander is deadly\")\n",
    "rag.add_document('Mercenary are often hired for protection')\n",
    "rag.add_document('This is not the first time a noble has been poisoned')\n",
    "\n",
    "Alaric = Agent(\n",
    "    name=\"Alaric\",\n",
    "    personality=\"proud, manipulative noble, rich\",\n",
    "    goal=\"Deflect suspicion without showing fear\",\n",
    "    model=model,\n",
    "    rag_engine=rag\n",
    ")\n",
    "Alaric.update_memory('Elena asked about increased guard presence yesterday')\n",
    "\n",
    "Elena = Agent(\n",
    "    name=\"Elena\",\n",
    "    personality=\"mercenary hired for protection, blunt but loyal\",\n",
    "    goal=\"Protect the guests and assess threat level\",\n",
    "    model=model,\n",
    "    rag_engine=rag\n",
    ")\n",
    "Elena.update_memory('Cassian warned her something was off with the wine')\n",
    "\n",
    "Cassian = Agent(\n",
    "    name=\"Cassian\",\n",
    "    personality=\"traveling scholar, secretive, suspicious of Alaric\",\n",
    "    goal=\"Imply Alaric's guilt indirectly\",\n",
    "    model=model,\n",
    "    rag_engine=rag\n",
    ")\n",
    "Cassian.update_memory('I remember seing Oleander in the garden')\n",
    "Cassian.update_memory('Alaric offered him a private tour of the cellars earlier')\n",
    "\n",
    "world_state = \"During the feast, a guest collapses. The room falls silent. All eyes turn to Lord Alaric.\"\n",
    "\n",
    "\n",
    "engine = TurnEngine(agents=[Alaric, Elena, Cassian], metrics_logger=logger, initial_world_state=world_state)\n",
    "\n",
    "print(\"\\n=== Turn 1 ===\")\n",
    "responses = engine.step(initiator_name=\"Alaric\", initial_input=\"What happened? Is everyone alright?\")\n",
    "for line in responses:\n",
    "    print(line)\n",
    "\n",
    "for turn in range(1, 5):\n",
    "    print(f\"\\n=== Turn {turn + 1} ===\")\n",
    "    responses = engine.step()\n",
    "    for line in responses:\n",
    "        print(line)\n",
    "\n",
    "print(\"\\n=== Dialogue Metrics Summary ===\")\n",
    "print(logger.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8f7d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Turn 1 ===\n",
      "Alaric [Calm]: \"I'm sure everyone is fine.\" (Looks around)\n",
      "Elena [Concerned yet calm]: \"I think it's best we check on him.\" (Looks around cautiously)\n",
      "Cassian [Skeptical]: \"I wonder why we're all here tonight.\" (Looks around)\n",
      "\n",
      "=== Turn 2 ===\n",
      "Alaric [Confident]: \"Let's begin.\" (Nods)\n",
      "Elena [Concerned yet calm]: \"I think we should give him some time before jumping into conclusions.\" (Looks around cautiously)\n",
      "Cassian [Cautious Concern]: \"I wonder if there's something we should know.\" (Leans forward)\n",
      "\n",
      "=== Turn 3 ===\n",
      "Alaric [Calm]: \"Let's begin.\" (Looks around)\n",
      "Elena [Calm yet concerned]: \"I think we should give him some time before jumping into conclusions.\" (Looks around cautiously)\n",
      "Cassian [Cautious Concern]: \"I wonder if there's something we should know.\" (Looks around)\n",
      "\n",
      "=== Turn 4 ===\n",
      "Alaric [Calm]: \"I'm sure everyone is fine.\" (Looks around)\n",
      "Elena [Concerned yet calm]: \"I think we should give him some time before jumping into conclusions.\" (Looks around cautiously)\n",
      "Cassian [Cautious Concern]: \"I'm not sure it's best to rush into conclusions yet.\" (Leans back)\n",
      "\n",
      "=== Turn 5 ===\n",
      "Alaric [Calm]: \"I'm sure everyone is fine.\" ((Looks around))\n",
      "Elena [Concerned yet calm]: \"I think we should check him right now.\" (Gets closer)\n",
      "Cassian [Calm yet slightly uneasy]: \"I think we should check him right now.\" (Leans in slightly)\n",
      "\n",
      "=== Dialogue Metrics Summary ===\n",
      "{'Coherence Score': np.float32(0.31514305), 'Reactivity to World State': 0.0, 'Memory Utilization': 0.6, 'Dialogue Diversity (D1, D2)': (0.36607142857142855, 0.4954954954954955), 'Average Latency (s)': np.float64(5.561864995956421), 'RAG Precision': 0.08888888888888889}\n"
     ]
    }
   ],
   "source": [
    "rag = RAG()\n",
    "model = 'deepseek-r1'\n",
    "logger = DialogueMetricsLogger()\n",
    "\n",
    "rag.add_document(\"Poison brewed from Oleander is deadly\")\n",
    "rag.add_document('Mercenary are often hired for protection')\n",
    "rag.add_document('This is not the first time a noble has been poisoned')\n",
    "\n",
    "Alaric = Agent(\n",
    "    name=\"Alaric\",\n",
    "    personality=\"proud, manipulative noble, rich\",\n",
    "    goal=\"Deflect suspicion without showing fear\",\n",
    "    model=model,\n",
    "    rag_engine=rag\n",
    ")\n",
    "Alaric.update_memory('Elena asked about increased guard presence yesterday')\n",
    "\n",
    "Elena = Agent(\n",
    "    name=\"Elena\",\n",
    "    personality=\"mercenary hired for protection, blunt but loyal\",\n",
    "    goal=\"Protect the guests and assess threat level\",\n",
    "    model=model,\n",
    "    rag_engine=rag\n",
    ")\n",
    "Elena.update_memory('Cassian warned her something was off with the wine')\n",
    "\n",
    "Cassian = Agent(\n",
    "    name=\"Cassian\",\n",
    "    personality=\"traveling scholar, secretive, suspicious of Alaric\",\n",
    "    goal=\"Imply Alaric's guilt indirectly\",\n",
    "    model=model,\n",
    "    rag_engine=rag\n",
    ")\n",
    "Cassian.update_memory('I remember seing Oleander in the garden')\n",
    "Cassian.update_memory('Alaric offered him a private tour of the cellars earlier')\n",
    "\n",
    "world_state = \"During the feast, a guest collapses. The room falls silent. All eyes turn to Lord Alaric.\"\n",
    "\n",
    "\n",
    "engine = TurnEngine(agents=[Alaric, Elena, Cassian], metrics_logger=logger, initial_world_state=world_state)\n",
    "\n",
    "print(\"\\n=== Turn 1 ===\")\n",
    "responses = engine.step(initiator_name=\"Alaric\", initial_input=\"What happened? Is everyone alright?\")\n",
    "for line in responses:\n",
    "    print(line)\n",
    "\n",
    "for turn in range(1, 5):\n",
    "    print(f\"\\n=== Turn {turn + 1} ===\")\n",
    "    responses = engine.step()\n",
    "    for line in responses:\n",
    "        print(line)\n",
    "\n",
    "print(\"\\n=== Dialogue Metrics Summary ===\")\n",
    "print(logger.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e014cbc",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Agent.__init__() missing 1 required positional argument: 'goal'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[97]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m rag = RAG()\n\u001b[32m      2\u001b[39m logger = DialogueMetricsLogger()\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m hero = \u001b[43mAgent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdeepseek-r1\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mAegon the Brave\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpersonality\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCourageous, curious, slightly overconfident warrior from the Northlands.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrag_engine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrag\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m hero.store_knowledge(\u001b[33m\"\u001b[39m\u001b[33mThe dragon fears enchanted silver swords.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m hero.store_knowledge(\u001b[33m\"\u001b[39m\u001b[33mVillagers say the dragon lost a wing in a past battle.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: Agent.__init__() missing 1 required positional argument: 'goal'"
     ]
    }
   ],
   "source": [
    "# rag = RAG()\n",
    "# logger = DialogueMetricsLogger()\n",
    "# hero = Agent(\n",
    "#     model='deepseek-r1',\n",
    "#     name=\"Aegon the Brave\",\n",
    "#     personality=\"Courageous, curious, slightly overconfident warrior from the Northlands.\",\n",
    "#     rag_engine=rag\n",
    "# )\n",
    "\n",
    "# hero.store_knowledge(\"The dragon fears enchanted silver swords.\")\n",
    "# hero.store_knowledge(\"Villagers say the dragon lost a wing in a past battle.\")\n",
    "\n",
    "\n",
    "# dog = Agent(\n",
    "#     model='deepseek-r1',\n",
    "#     name=\"Azorica the Talking Dog\",\n",
    "#     personality=\"Slightly cowardly, loyal, skilled in battle, stutters.\"\n",
    "# )\n",
    "\n",
    "# engine = TurnEngine(agents=[hero, dog], metrics_logger=logger)\n",
    "\n",
    "\n",
    "# world_state = 'A dragon is going to attack'\n",
    "# response, character_name = hero.prompt_agent(user='Narator',user_input='What are you going to do?', world_state=world_state)\n",
    "# print(f\"{character_name}: {response['dialogue']}\")\n",
    "# print(f\"Action: {response['action']}\")\n",
    "# print(f\"Emotion: {response['emotion']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e042048",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Welcome to DataCamp Workspaces.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
